import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import HeteroConv, SAGEConv, Linear
import torch.optim as optim
import time
from tqdm import tqdm
from sklearn.metrics import mean_squared_error


class RecipeRecommenderGNN(nn.Module):
    """
    Graph Neural Network for personalized recipe recommendation.

    This model builds embeddings for users, recipes, and other related entities
    (ingredients, tags, review words, etc.) using a heterogeneous graph structure.
    It applies multi-layer SAGE-style convolutions for message passing across the graph.
    """
    def __init__(self, metadata, hidden_channels=64, out_channels=64, num_layers=2):
        super().__init__()
        self.embeddings = nn.ModuleDict()

        # Create learnable embeddings for all node types except 'recipe'
        for node_type in metadata[0]:
            if node_type != 'recipe':
                self.embeddings[node_type] = nn.Embedding(100000, hidden_channels)

        # Recipes already have features, so project them into the embedding space
        self.input_linear = Linear(9, hidden_channels)

        # Define multiple heterogeneous graph convolution layers
        self.convs = nn.ModuleList()
        for _ in range(num_layers):
            conv = HeteroConv({
                edge_type: SAGEConv((-1, -1), hidden_channels)
                for edge_type in metadata[1]
            }, aggr='sum')
            self.convs.append(conv)

        # Linear projections for final user and recipe embeddings
        self.lin_user = Linear(hidden_channels, out_channels)
        self.lin_recipe = Linear(hidden_channels, out_channels)

    def forward(self, x_dict, edge_index_dict, num_nodes_dict=None):
        """
        Perform forward pass and generate embeddings for each node type.
        """
        x_dict_out = {}
        for node_type in x_dict:
            if node_type == 'recipe':
                x_dict_out[node_type] = self.input_linear(x_dict[node_type])
            else:
                x_dict_out[node_type] = self.embeddings[node_type](x_dict[node_type])

        for conv in self.convs:
            prev_dict = x_dict_out
            x_dict_out_new = conv(prev_dict, edge_index_dict)

            # Keep previous embeddings if this layer didn't update a node type
            for node_type in prev_dict:
                if node_type not in x_dict_out_new or x_dict_out_new[node_type] is None:
                    x_dict_out_new[node_type] = prev_dict[node_type]

            x_dict_out = {k: F.relu(v) for k, v in x_dict_out_new.items()}

        return x_dict_out

    def predict(self, x_user, x_recipe):
        """
        Compute a relevance score between user and recipe embeddings using dot product.
        """
        u = self.lin_user(x_user)
        r = self.lin_recipe(x_recipe)
        return (u * r).sum(dim=-1)


class RecommenderDeployWrapper(torch.nn.Module):
    """
    TorchScript-compatible wrapper for deploying the recommendation model.

    This wrapper takes the final user and recipe embeddings and allows computing
    scores for a specific user against all recipes.
    """
    def __init__(self, model, user_embed, recipe_embed):
        super().__init__()
        self.user_proj = model.lin_user
        self.recipe_proj = model.lin_recipe
        self.user_embed = user_embed
        self.recipe_embed = recipe_embed

    def forward(self, user_id: int):
        u = self.user_proj(self.user_embed[user_id])
        r = self.recipe_proj(self.recipe_embed)
        scores = (u * r).sum(dim=1)
        return scores


def export_script_model(model, out_dict, path="recipe_gnn_script_100k.pt"):
    """
    Export the trained model as a TorchScript file for production deployment.
    """
    wrapper = RecommenderDeployWrapper(
        model,
        out_dict['user'].detach(),
        out_dict['recipe'].detach()
    )
    wrapper.eval()
    script = torch.jit.script(wrapper)
    script.save(path)
    print(f"TorchScript model saved to {path}")


def get_pos_neg_edges(data, num_neg=1):
    """
    Generate positive and negative user-recipe interaction pairs.

    Positive samples are from actual interactions.
    Negative samples are generated by randomly pairing users with other recipes.
    """
    pos_u, pos_r = data['user', 'rates', 'recipe'].edge_index
    num_pos = pos_u.size(0)
    neg_u = pos_u.repeat_interleave(num_neg)
    neg_r = torch.randint(0, data['recipe'].num_nodes, (num_pos * num_neg,), device=pos_u.device)
    return pos_u, pos_r, neg_u, neg_r


def main():
    # Load the heterogeneous recipe graph
    data = torch.load("recipe_graph_100k.pt")
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    data = data.to(device)

    # Ensure every expected edge type has a defined edge index
    for edge_type in data.metadata()[1]:
        if edge_type not in data.edge_index_dict or data.edge_index_dict[edge_type] is None:
            data.edge_index_dict[edge_type] = torch.empty((2, 0), dtype=torch.long, device=device)

    # Initialize model and optimizer
    model = RecipeRecommenderGNN(metadata=data.metadata()).to(device)
    optimizer = optim.Adam(model.parameters(), lr=1e-3)

    EPOCHS = 10
    print("\nStarting training...\n")

    for epoch in range(1, EPOCHS + 1):
        model.train()
        optimizer.zero_grad()
        start = time.time()

        # Build input feature dictionaries
        x_dict = {}
        for node_type in data.metadata()[0]:
            if node_type == 'recipe':
                x_dict[node_type] = data[node_type].x
            else:
                if node_type not in data.num_nodes_dict:
                    raise ValueError(f"Node type '{node_type}' not found in data.num_nodes_dict.")
                x_dict[node_type] = torch.arange(data.num_nodes_dict[node_type], device=device)

        # Generate updated embeddings
        out_dict = model(x_dict, data.edge_index_dict, data.num_nodes_dict)

        # Generate positive and negative training pairs
        pos_u, pos_r, neg_u, neg_r = get_pos_neg_edges(data)

        pos_scores = model.predict(out_dict['user'][pos_u], out_dict['recipe'][pos_r])
        neg_scores = model.predict(out_dict['user'][neg_u], out_dict['recipe'][neg_r])

        # Create binary labels and scores for classification
        labels = torch.cat([torch.ones_like(pos_scores), torch.zeros_like(neg_scores)])
        scores = torch.cat([pos_scores, neg_scores])

        # Compute loss and update weights
        loss = F.binary_cross_entropy_with_logits(scores, labels)
        loss.backward()
        optimizer.step()

        print(f"Epoch {epoch}/{EPOCHS} — Loss: {loss.item():.4f} — Time: {time.time() - start:.2f}s")

    print("\nTraining complete!")

    # Export the final model
    print("Exporting model...")
    model.eval()

    x_dict = {}
    for node_type in data.metadata()[0]:
        if node_type == 'recipe':
            x_dict[node_type] = data[node_type].x
        else:
            x_dict[node_type] = torch.arange(data.num_nodes_dict[node_type], device=device)

    final_embs = model(x_dict, data.edge_index_dict, data.num_nodes_dict)
    export_script_model(model, final_embs)

    # Save model checkpoint for later evaluation
    torch.save(model.state_dict(), "recipe_model.pt")


class RecipeGNNModel:
    """
    Wrapper around RecipeRecommenderGNN for evaluation using a shared interface.
    """

    def __init__(self, model, data, device):
        self.model = model.eval()
        self.data = data
        self.device = device
        self.out_dict = self._generate_embeddings()

    def _generate_embeddings(self):
        x_dict = {}
        for node_type in self.data.metadata()[0]:
            if node_type == 'recipe':
                x_dict[node_type] = self.data[node_type].x
            else:
                x_dict[node_type] = torch.arange(self.data.num_nodes_dict[node_type], device=self.device)

        return self.model(x_dict, self.data.edge_index_dict, self.data.num_nodes_dict)

    def evaluate(self):
        """
        Compute RMSE on all positive user-recipe edges.
        """
        pos_u, pos_r = self.data['user', 'rates', 'recipe'].edge_index

        with torch.no_grad():
            pred_scores = self.model.predict(
                self.out_dict['user'][pos_u],
                self.out_dict['recipe'][pos_r]
            ).sigmoid()  # Convert logits to probabilities

        true_scores = torch.ones_like(pred_scores)
        rmse = mean_squared_error(true_scores.cpu(), pred_scores.cpu(), squared=False)
        return rmse


if __name__ == "__main__":
    main()
